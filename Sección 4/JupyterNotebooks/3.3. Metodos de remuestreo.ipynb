{"cells":[{"cell_type":"markdown","metadata":{"id":"nXELYPn4tSh4"},"source":["<h2><font color=\"#004D7F\" size=6>Módulo 3. Preprocesamiento de datos</font></h2>\n","\n","\n","\n","<h1><font color=\"#004D7F\" size=5>3. Métodos de remuestreo</font></h1>\n","\n","<br><br>\n","<div style=\"text-align: right\">\n","<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n","<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"]},{"cell_type":"markdown","metadata":{"id":"LZbPkWxBtSiE"},"source":["---\n","\n","<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n","<a id=\"indice\"></a>\n","\n","* [1. Introducción](#section1)\n","    * [1.1. Librerías y CSV](#section11)\n","* [2. Validación cruzada](#section2)\n","    * [2.1. _k_-fold Cross Validation](#section21)\n","    * [2.2. Validación cruzada repetida](#section22)\n","    * [2.3. Validación cruzada dejando uno fuera](#section23)\n","* [3. División en porcentaje](#section3)\n","    * [3.1. División en porcentaje train/test](#section31)\n","    * [3.2. División train/test repetidos aleatoriamente](#section32)\n","* [4. Qué técnica usar](#section4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6TFdmRKtSiG","outputId":"6c5d8857-7112-44a6-cfb9-e88670b9a1f9"},"outputs":[{"data":{"text/html":["<style>.container{ width:98% }</style>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n","from IPython.core.display import display, HTML\n","display(HTML(\"<style>.container{ width:98% }</style>\"))"]},{"cell_type":"markdown","metadata":{"id":"nTG8-mICtSiL"},"source":["---\n","<a id=\"section1\"></a>\n","# <font color=\"#004D7F\"> 1. Introducción</font>"]},{"cell_type":"markdown","metadata":{"id":"gWRyGmEztSiM"},"source":["La evaluación es una estimación que podemos usar para hablar sobre qué tan bien creemos que el algoritmo realmente puede funcionar en la práctica. No es una garantía de rendimiento. Una vez que estimamos el rendimiento de nuestro algoritmo, podemos volver a entrenar el algoritmo final en todo el conjunto de datos de entrenamiento y prepararlo para su uso operativo. A continuación, veremos cuatro técnicas diferentes que podemos usar para dividir nuestro conjunto de datos de entrenamiento y crear estimaciones útiles de rendimiento para nuestros algoritmos de Machine Learning:\n","* Cómo dividir un conjunto de datos en subconjuntos por porcentaje para entrenamiento/validación.\n","* Cómo evaluar la robustez del modelo utilizando la validación cruzada, k-fold, con y sin repeticiones.\n","* Cómo evaluar la robustez del modelo usando una validación cruzada dejando uno fuera (LOOCV).\n","* División en train/test repetidos aleatoriamente."]},{"cell_type":"markdown","metadata":{"id":"UuDe5UfktSiN"},"source":["<a id=\"section11\"></a>\n","## <font color=\"#004D7F\"> 1.1. Librerías y CSV</font>"]},{"cell_type":"markdown","metadata":{"id":"7EgIFvn6tSiO"},"source":["Como siempre cargamos el CSV que vamos a utilizar. Así mismo, vamos a cargar las librerías principales que utilizaremos en esta sección."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUkxNCIEtSiP","executionInfo":{"status":"ok","timestamp":1708033426830,"user_tz":-60,"elapsed":433,"user":{"displayName":"Iñigo Osés","userId":"10976997508865545670"}},"outputId":"95599fd3-47cd-492f-ec3b-1b069a383a7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[  6.  148.   72.  ...  33.6 627.   50. ]\n"," [  1.   85.   66.  ...  26.6 351.   31. ]\n"," [  8.  183.   64.  ...  23.3 672.   32. ]\n"," ...\n"," [  5.  121.   72.  ...  26.2 245.   30. ]\n"," [  1.  126.   60.  ...  30.1 349.   47. ]\n"," [  1.   93.   70.  ...  30.4 315.   23. ]]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","\n","filename = \"pima-indians-diabetes.csv\"\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","data = pd.read_csv(filename, names=names)\n","array = data.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","print(X)"]},{"cell_type":"markdown","metadata":{"id":"3CJ2FRxYtSiQ"},"source":["<div style=\"text-align: right\"> <font size=5>\n","    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n","</font></div>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"kwU6jUj4tSiS"},"source":["<a id=\"section2\"></a>\n","# <font color=\"#004D7F\"> 2. Validación cruzada</font>"]},{"cell_type":"markdown","metadata":{"id":"B0zDHqg_tSiT"},"source":["La validación cruzada es un proceso en la que se realizan $K$ particiones o **folds** de la base de datos y con ellos se realizan $K$ evaluaciones diferentes, de tal forma que todos los casos por lo menos una vez se encuentran en el conjunto de test. Básicamente en la evaluación $i$, la partición $i$ son los casos de test y el resto son los casos de entrenamiento. Finalmente, se realiza una media de los resultados obtenidos en las diferentes evaluaciones. En la siguiente imagen se ve un ejemplo de esto.\n","\n","<img src=\"https://static.oschina.net/uploads/img/201609/26155106_OfXx.png\" alt=\"cross-validation\" width=\"500\">"]},{"cell_type":"markdown","metadata":{"id":"zhTzWy7dtSiU"},"source":["<a id=\"section21\"></a>\n","## <font color=\"#004D7F\"> 2.1. _k_-fold Cross Validation</font>"]},{"cell_type":"markdown","metadata":{"id":"w2nG0731tSiU"},"source":["El método de validación cruzada de _k-fold_ implica dividir el conjunto de datos en _k_-particiones, también llamados _fold_. Cada subconjunto se mantiene mientras el modelo se entrena en todos los demás particiones. Este proceso se repite hasta que se determina la precisión para cada instancia en el conjunto de datos, y se proporciona una estimación de precisión general. Es un método robusto para estimar la precisión, y el tamaño de _k_ puede ajustar la cantidad de sesgo en la estimación, con valores populares establecidos en 5 y 10.\n","\n","Puede ver que informamos tanto la media como la desviación estándar de la medida de rendimiento. Al resumir las medidas de rendimiento, es una buena práctica resumir la distribución de las medidas, en este caso suponiendo una distribución gaussiana del rendimiento (un supuesto muy razonable) y registrando la desviación estándar y media."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgwLwZnptSiV","executionInfo":{"status":"ok","timestamp":1708034234210,"user_tz":-60,"elapsed":373,"user":{"displayName":"Iñigo Osés","userId":"10976997508865545670"}},"outputId":"e76455bf-785e-4924-d09a-51d56f4014d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 77.34% (4.90%)\n"]}],"source":["# Evaluate using Cross Validation\n","from sklearn.model_selection import KFold #Validación cruzada\n","from sklearn.model_selection import cross_val_score #calcula el score\n","from sklearn.linear_model import LogisticRegression #algoritmo de regresion logística\n","\n"," # es el número de conjuntos en los que se divide\n","num_folds = 10\n","#asegura que da siempre los mismos resultados\n","seed = 7\n","kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n","\n","model = LogisticRegression(solver='lbfgs', max_iter=1000)   #solver es un hiperparametro\n","\n","results = cross_val_score(model, X, Y, cv = kfold)\n","\n","print(f\"Accuracy = {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)\") #calcula la media de las ietarciones\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BVKTVlO7tSiV"},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n","Puede obtener más información en la documentación oficial de Scikit-Learn sobre la clase [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=kfold#sklearn.model_selection.KFold).\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"758qi71xtSiW"},"source":["<a id=\"section22\"></a>\n","## <font color=\"#004D7F\"> 2.2. Validación cruzada repetida</font>"]},{"cell_type":"markdown","metadata":{"id":"VhaBH9VrtSiW"},"source":["Una extensión de esta técnica de entrenamiento/validación es el poder repetir varias veces el proceso de dividir los datos _k-fold_. En este caso, la precisión final del modelo se toma como la media del número de repeticiones.\n","\n","Al igual que el caso anterior podemos observar que nos informa tanto la media como la desviación estándar de la medida de rendimiento."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ps6hJYTtSiW","executionInfo":{"status":"ok","timestamp":1708034357234,"user_tz":-60,"elapsed":1521,"user":{"displayName":"Iñigo Osés","userId":"10976997508865545670"}},"outputId":"c3e3810a-75c6-44c8-9f42-30ad2dc19370"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 77.32% (4.15%)\n"]}],"source":["# Evaluate using Leave One Out Cross Validation\n","# Evaluate using Cross Validation\n","from sklearn.model_selection import RepeatedKFold #Validación cruzada\n","from sklearn.model_selection import cross_val_score #calcula el score\n","from sklearn.linear_model import LogisticRegression #algoritmo de regresion logística\n","\n"," # es el número de conjuntos en los que se divide\n","num_folds = 10\n","#asegura que da siempre los mismos resultados\n","seed = 7\n","#Numero de repeticiones\n","num_repeated = 5\n","repeatedkfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeated, random_state=seed)\n","\n","model = LogisticRegression(solver='lbfgs', max_iter=1000)   #solver es un hiperparametro\n","\n","results = cross_val_score(model, X, Y, cv = repeatedkfold)\n","\n","print(f\"Accuracy = {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)\") #calcula la media de las ietarciones"]},{"cell_type":"markdown","metadata":{"id":"lMKazOm7tSiX"},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n","Puede obtener más información en la documentación oficial de Scikit-Learn sobre la clase [`RepeatedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html?highlight=kfold#sklearn.model_selection.RepeatedKFold).\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"23JxFP9HtSiX"},"source":["<a id=\"section23\"></a>\n","## <font color=\"#004D7F\"> 2.3. Validación cruzada dejando uno fuera</font>"]},{"cell_type":"markdown","metadata":{"id":"zlXen8JptSiX"},"source":["En Validación cruzada dejando uno fuera (Leave One Out Cross Validation, LOOCV), se omite una instancia de datos y se construye un modelo en todas las demás instancias de datos en el conjunto de entrenamiento, repitiéndose este proceso para todas las instancias de datos. El resultado es una gran cantidad de medidas de rendimiento que se pueden resumir en un esfuerzo por proporcionar una estimación más razonable del _Accuracy_ de su modelo.\n","\n","Puede ver en la desviación estándar que la puntuación tiene más varianza que los resultados de validación cruzada _k-fold_ descritos anteriormente."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ea_oELVItSiY","executionInfo":{"status":"ok","timestamp":1708034681702,"user_tz":-60,"elapsed":25352,"user":{"displayName":"Iñigo Osés","userId":"10976997508865545670"}},"outputId":"881f9eae-523d-4e8e-f69a-469380a59c59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 77.47% (41.78%)\n"]}],"source":["# Evaluate using Leave One Out Cross Validation\n","\n","from sklearn.model_selection import LeaveOneOut #Validación cruzada\n","from sklearn.model_selection import cross_val_score #calcula el score\n","from sklearn.linear_model import LogisticRegression #algoritmo de regresion logística\n","\n","loocv = LeaveOneOut()\n","model = LogisticRegression(solver = 'lbfgs', max_iter = 1000)\n","\n","results = cross_val_score(model, X, Y, cv=loocv)\n","\n","print(f\"Accuracy = {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)\") #calcula la media de las ietarciones"]},{"cell_type":"markdown","metadata":{"id":"_MEbYBeotSiY"},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n","Puede obtener más información en la documentación oficial de Scikit-Learn sobre la clase [`LeaveOneOut`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html?highlight=leaveoneout#sklearn.model_selection.LeaveOneOut).\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"e2wljcSKtSiZ"},"source":["<div style=\"text-align: right\"> <font size=5>\n","    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n","</font></div>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"fx_p2USUtSiZ"},"source":["<a id=\"section3\"></a>\n","# <font color=\"#004D7F\"> 3. División en porcentaje</font>"]},{"cell_type":"markdown","metadata":{"id":"4Kjjct9ttSiZ"},"source":["<a id=\"section31\"></a>\n","## <font color=\"#004D7F\"> 3.1. División en porcentaje train/test</font>"]},{"cell_type":"markdown","metadata":{"id":"_Kzk_DiwtSiZ"},"source":["La división de datos implica la partición de los datos en un conjunto de datos de entrenamiento explícito utilizado para preparar el modelo y un conjunto de datos de validación invisible (se dice validación invisible ya que aunque se conozca el atributo clase el modelo lo omitirá para una vez realizada la predicción compararlo para ver si ha acertado) que se utiliza para evaluar el rendimiento del modelo en datos no etiquetados.\n","\n","En el ejemplo a continuación, dividimos el conjunto de datos de los indios Pima en divisiones de 67%/33% para entrenamiento y prueba y evaluar el Accuracy de un modelo Logistic Regression."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AN3Q_WRptSiZ","executionInfo":{"status":"ok","timestamp":1708035086435,"user_tz":-60,"elapsed":515,"user":{"displayName":"Iñigo Osés","userId":"10976997508865545670"}},"outputId":"076a1084-3176-42c2-81e9-10af20f903a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 78.74% \n"]}],"source":["# Evaluate using a train and a test set\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","test_size = 0.33\n","seed = 7\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= test_size, random_state=seed)\n","\n","model = LogisticRegression(solver='lbfgs', max_iter=1000)\n","model.fit(X_train, Y_train)\n","\n","results = model.score(X_test, Y_test)\n","\n","print(f\"Accuracy = {results*100.0:,.2f}% \") #calcula la media de las ietarciones\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lzw8ZzYytSia"},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n","Puede obtener más información en la documentación oficial de Scikit-Learn sobre la clase [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split).\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"yNh0-t_EtSia"},"source":["<a id=\"section32\"></a>\n","## <font color=\"#004D7F\"> 3.2. División train/test repetidos aleatoriamente</font>"]},{"cell_type":"markdown","metadata":{"id":"e74zyb1StSia"},"source":["Otra variación en la validación cruzada de k-fold es crear una división aleatoria de los datos como la división de train/test descrita anteriormente, pero repetir el proceso de división y evaluación del algoritmo varias veces, como la validación cruzada. El siguiente ejemplo divide los datos en una división de train/test del 67%/33% y repite el proceso 10 veces.\n","\n","Podemos ver que en este caso la distribución de la medida de desempeño está a la par con _k_-fold cross validation pero reducimos la varianza considerablemente."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3faQho75tSib","executionInfo":{"status":"ok","timestamp":1708035630897,"user_tz":-60,"elapsed":403,"user":{"displayName":"Iñigo Osés","userId":"10976997508865545670"}},"outputId":"4650316c-b88e-4ec9-feb3-7206948d7bdd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 76.61% (2.32%)\n"]}],"source":["# Evaluate using Shuffle Split Cross Validation\n","from sklearn.model_selection import ShuffleSplit\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","test_size = 0.33\n","seed = 7\n","n_splits = 10\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= test_size, random_state=seed)\n","\n","kfold = ShuffleSplit(n_splits=n_splits, test_size = test_size, random_state=seed)\n","model = LogisticRegression(solver ='lbfgs', max_iter=1000)\n","\n","results = cross_val_score(model, X, Y, cv =kfold)\n","\n","print(f\"Accuracy = {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)\") #calcula la media de las ietarciones"]},{"cell_type":"markdown","metadata":{"id":"do31VrULtSic"},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n","Puede obtener más información en la documentación oficial de Scikit-Learn sobre la clase [`ShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html?highlight=shufflesplit#sklearn.model_selection.ShuffleSplit).\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"yQd2TgCOtSid"},"source":["<div style=\"text-align: right\"> <font size=5>\n","    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n","</font></div>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"m1Azvb1WtSid"},"source":["<a id=\"section4\"></a>\n","# <font color=\"#004D7F\"> 4. Qué técnica usar</font>"]},{"cell_type":"markdown","metadata":{"id":"HNanli8QtSie"},"source":["Esta sección enumera algunos consejos para considerar qué técnica de remuestreo usar en diferentes circunstancias.\n","* Por lo general, la validación cruzada de _k-fold_ es el estándar defacto para evaluar el rendimiento de un algoritmo en datos no etiquetados con _k_ configurado en 3, 5 o 10.\n","* El uso de una división de train/test es buena para la velocidad cuando se usa un algoritmo lento y produce estimaciones de rendimiento con un sesgo más bajo cuando se usan conjuntos de datos grandes.\n","* Las técnicas como LOOCV y las divisiones aleatorias repetidas pueden ser intermedios útiles cuando se trata de equilibrar la variación en el rendimiento estimado, la velocidad de entrenamiento del modelo y el tamaño del conjunto de datos.\n","\n","El mejor consejo es experimentar y encontrar una técnica para su problema que sea rápida y produzca estimaciones razonables de rendimiento que pueda usar para tomar decisiones. En caso de duda, utilice la validación cruzada con un _k-fold_ de 10."]},{"cell_type":"markdown","metadata":{"id":"zHimTETNtSie"},"source":["<div style=\"text-align: right\"> <font size=5>\n","    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n","</font></div>\n","\n","---\n","\n","<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}